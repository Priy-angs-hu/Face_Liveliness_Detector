{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3dd2fd4-1693-4827-b4ac-670cc4d115cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49056c46-e745-4690-8367-86d769731adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_all_videos(root_dir, frame_dir, sample_rate=5):\n",
    "    for folder in os.listdir(root_dir):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for video_file in os.listdir(folder_path):\n",
    "                if video_file.endswith('.mp4'):\n",
    "                    video_path = os.path.join(folder_path, video_file)\n",
    "                    video_frame_dir = os.path.join(frame_dir, folder)\n",
    "                    if not os.path.exists(video_frame_dir):\n",
    "                        os.makedirs(video_frame_dir)\n",
    "                    extract_frames(video_path, video_frame_dir, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff329ece-f318-4106-bd04-28a07f5c8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_frames(video_path, frame_dir, sample_rate=5):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % sample_rate == 0:\n",
    "            cv2.imwrite(os.path.join(frame_dir, f'frame{count}.jpg'), frame)\n",
    "        count += 1\n",
    "    video.release()\n",
    "\n",
    "extract_frames_from_all_videos(r'C:\\Fce Auth\\dataset', r'C:\\Fce Auth\\frames')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2fca2b5-148d-4d86-b15f-89b09fa2a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset='training')\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset='validation')\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c529a7-f930-417d-9bd3-6a4f74ad664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 6 classes.\n",
      "Found 30 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen = load_data(r'C:\\Fce Auth\\frames')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2519903-370e-4586-833a-ac2858818504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd83aab-0a6e-44b2-9f17-9d413ba25e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_gen, val_gen, epochs=10):\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25f73ff-4b0d-41ec-bfc1-d63a59cf3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    frame_resized = cv2.resize(frame, (224, 224))\n",
    "    frame_array = image.img_to_array(frame_resized)\n",
    "    frame_array = np.expand_dims(frame_array, axis=0)\n",
    "    frame_array = frame_array / 255.0\n",
    "    return frame_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58831f25-d120-4016-bcdb-c976439e06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frame(frame, model):\n",
    "    processed_frame = preprocess_frame(frame)\n",
    "    prediction = model.predict(processed_frame)\n",
    "    return prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bfac200-a261-4295-b3ab-1cbb53ae3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_blank_frame(frame, threshold=30):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mean_intensity = np.mean(gray_frame)\n",
    "    return mean_intensity < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59093a7d-2097-4240-9dfb-f6493708e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_prediction(model):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Unable to get image\")\n",
    "            continue\n",
    "\n",
    "        if is_blank_frame(frame):\n",
    "            cv2.putText(frame, 'Unable to get image', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            prediction = predict_frame(frame, model)\n",
    "            label = \"Real\" if prediction > 0.5 else \"Fake\"\n",
    "            confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "            label_text = f'{label}: {confidence:.2f}'\n",
    "            cv2.putText(frame, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Webcam Prediction', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a1fbd-e720-4ad9-abf3-6a4bf0628db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 6 classes.\n",
      "Found 30 images belonging to 6 classes.\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset_path = r'C:\\Fce Auth\\frames'\n",
    "    train_gen, val_gen = load_data(dataset_path)\n",
    "    model = create_model()\n",
    "    trained_model = train_model(model, train_gen, val_gen)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfeadf7-a486-432c-9f7a-677a48e9291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  webcam_prediction(trained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
